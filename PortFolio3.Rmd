---
title: "Portfolio 3"
author: "Martine Lind Jensen"
date: "12/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(pacman)

pacman::p_load(tidyverse, pastecs, WRS2, stringi, stringr, anytime)
```


```{r loading data, error = FALSE, warning=FALSE, message=FALSE}
#get a vector with names of files using list.files() 
files <- list.files(path = "data",   
                    pattern = ".csv",  #everything that contains '.csv' in its name will be listed
                    full.names = T)    #makes it include directory path, so instead of 'logfile_1.csv' it will be 'data/logfile_1.csv')

#read all the files into a tibble 
data <- lapply(files, read_csv) %>%  
  plyr::rbind.fill()  

#Changing to numeric 
data$Response_Time <- as.numeric(data$Response_Time)

#Removing na
data <- na.omit(data)

#Removing wrong words 
data <- filter(data, Word != "ago,the")

```

***Part 1: Correlation analysis of word length, word frequency and word number***

Which properties of words correlate with word-by-word reading times?


**Testing assumptions for response time data.**

```{r assumptions response time}
#Checking if response_time data is normally distributed 
#Histogram response_time data 
ggplot(data, aes(x = data$Response_Time)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.25) +
  ggtitle("Are response_time data normally distributed") +
  stat_function(fun = dnorm, args = list(mean = mean(data$Response_Time, na.rm = TRUE), sd = sd(data$Response_Time, na.rm = TRUE)), colour= "darkgreen", size = 1)+
  theme_classic()

#qqplot response_time data
qqnorm(data$Response_Time)

#Descriptive stats response_time data 
round(pastecs::stat.desc(data$Response_Time, basic = FALSE, norm = TRUE), digits = 2)
```

The data are not normally distributed, therefore i've tried to transform the data and remove the outliers. Then i've checked for normality.

```{r assumptions log response time}
#The data are not normally distributed 
data_log <- data %>% mutate(rt_log = log(data$Response_Time)) #log transformation

#Removing outliers
data_log$z <- (data_log$rt_log-mean(data_log$rt_log))/sd(data_log$rt_log)

data_log <- filter(data_log, z < 3 & z > -3)

#Checking if rt_log data is normally distributed 
#Histogram response_time data 
ggplot(data_log, aes(x = data_log$rt_log)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.25) +
  ggtitle("Are log response time data normally distributed") +
  stat_function(fun = dnorm, args = list(mean = mean(data_log$rt_log, na.rm = TRUE), sd = sd(data_log$rt_log, na.rm = TRUE)), colour= "darkgreen", size = 1)+
  theme_classic()

#qqplot rt_log data
qqnorm(data_log$rt_log)

#Descriptive stats response_time data 
round(pastecs::stat.desc(data_log$rt_log, basic = FALSE, norm = TRUE), digits = 2)
```


The histogram, qqplot and all of the statistical tests doesn't approach normality. The p-value (p = .00) is very low, and the kurtosis (kurt.2SE > 1) and the skewness (skew.2SE > 1) are both bigger than one, which is very poor numbers for normally distributed data. 

We use response time in all of the correlation, and since that is not normally distributed, i have decided to use kendalls tau as a correlation test. Kendalls tau doesn't assume normality and probably works better with smaller data sets, and we work with a data set with 20 participants, which is small data set. 



**Testing correlation between word length and response time.**

Checking correlation between word length and response time. 

The hypothesis is that the longer the word is, the longer time it takes to read it. 

```{r correlation analysis word length}
#Making a new coloumn with word length 

#Removing all else than letters
data$Word <- str_replace_all(data$Word, "[:punct:]","")

#Counting letters in the word 
data$Word_length <- nchar(data$Word)

ggplot(data, aes(x = data$Word_length, y = data$Response_Time)) +
  geom_point(stat = "summary", fun.y = mean) +
  geom_smooth(method = "lm")

#Cant get spearman to work 
cor.test(data$Word_length, data$Response_Time, method = "kendall")

```


There is a very small increase in response time as the word becomes longer tau = .06 and p < 0.01. 

The correlation coeffecient (tau) is less than .1 which means that the effect size is almost non existing. But the p-value is less than .01, which means that the effect size is statistically significant.



**Testing correlation between word frequency and response time.**

Checking correlation between word frequency and response time.

The hypothesis is that the more frequent a word is, the less time it takes to read. 

```{r correlation analysis word frequency}
MRC <- read.csv("MRC_database.csv")

logfile <- data

#Rename the capitalized column to "word"
colnames(logfile)[colnames(logfile)=="Word"] <- "word"

#Convert your words into uppercase
logfile$word <- toupper(logfile$word)

#Mergin the two dataframes
data_freq <- merge(MRC, logfile, by = "word")

#Plotting the data 
ggplot(data_freq, aes(x = data_freq$kf_freq, y = data_freq$Response_Time)) +
  geom_point() +
  geom_smooth(method = "lm")

cor.test(data_freq$kf_freq, data_freq$Response_Time, method = "kendall")

```


There is no increase in response time as the word becomes less frequent tau = .01, p > 0.05. 


**Testing correlation between word number and response time.**

Checking correlation between the order of the word and the response time.

The hypothesis is that people get faster at reading, the further in the experiment they get. 

```{r correlation analysis word number}

#Plotting the data 
ggplot(data, aes(x = data$X1, y = data$Response_Time)) +
  geom_point(stat = "summary", fun.y = mean) +
  geom_smooth(method = "lm")

cor.test(data$X1, data$Response_Time, method = "kendall")
```


There is a small decrease in response time as the word number increases tau = .15, p < 0.01. 

The correlation coeffecient (tau) is bigger than .1 which is a small effect, and the p-value is less than .01, which means that the effect size is statistically significant.



**Conclusion part 1**

In the three properties of word-by-word reading we tested, only the word number showed a significantly effect. This could be because, as people get familiar with the experiment, they become faster at the task. And that could have an influence of the surprise word in our experiment, as it comes quite late in the text, where people tend to be faster. Perhaps because of boredom, perhaps because of experience with the experiment. 

The word length showed a very small effect, but our text did not include any high-level reading words, so maybe the effect would have been bigger, if the text included longer and harder words.

The word frequency showed no effect. We had a lot of odd words such as "airbender" and "avatar", so the database did not include a lot of the words in the text we used. This could have had an impact on the correlation test of frequency. 



***Part 2: Comparing means of the surprise word and the follow-up word across condition with t-test***

How do semantic-contextual expectations affect reading times?

Our hypothesis is that it takes longer time to read a semantically different word than a normal word. 


**Filtering data**

Filtering the data so i have two seperate dataframes containing the suprise/normal word ("kiss"/"save") and the follow-up word ("the")

```{r filtering data}

data_clean <- filter(data, X1>=81)

data_clean <- filter(data_clean, X1<=83)

data_clean <- filter(data_clean, Word != "can")

data_clean <- filter(data_clean, Word != "world")

the_df <- filter(data_clean, Word == "the")

ks_df <- filter(data_clean, Word != "the")

```

**Testing assumptions, transforming data and removing outliers**

Testing assumption of normality to find out which t-test to use. 
```{r assumptions the_df and ks_df}

#The data
#Histogram "the" data 
ggplot(the_df, aes(x = the_df$Response_Time)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.1) +
  ggtitle("Response time for the_df histogram") +
  stat_function(fun = dnorm, args = list(mean = mean(the_df$Response_Time, na.rm = TRUE), sd = sd(the_df$Response_Time, na.rm = TRUE)), colour= "darkgreen", size = 1)+
  theme_classic()

#qqplot "the" data
qqnorm(the_df$Response_Time)

#Descriptive stats "the" data 
round(pastecs::stat.desc(the_df$Response_Time, basic = FALSE, norm = TRUE), digits = 2)


#ks data
#Visual ks data 
ggplot(ks_df, aes(x = ks_df$Response_Time)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.1) +
  ggtitle("Resonse time for ks_df histogram") +
  stat_function(fun = dnorm, args = list(mean = mean(ks_df$Response_Time, na.rm = TRUE), sd = sd(ks_df$Response_Time, na.rm = TRUE)), colour= "darkgreen", size = 1)+
  theme_classic()

qqnorm(ks_df$Response_Time)

round(pastecs::stat.desc(ks_df$Response_Time, basic = FALSE, norm = TRUE), digits = 2)
```


The data is not normally distributed and i estimate that it wont be normal even if i transform and removing outliers.


**Making plots comparing the means**

Barplot of the follow-up word with standard error as errorbars.

```{r bar plot follow-up word}
#Follow up word "the" 
ggplot(the_df, aes(x = the_df$Condition, y = the_df$Response_Time)) +
  theme_minimal() +
    labs(x = "Condition", y = "Response time") +
  geom_bar(aes(fill= Condition), stat='summary', fun.y = mean, width = 0.5) +
  stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1) +
  ggtitle("The mean of the second word 'the' across conditions")
```


The plot shows no difference of the mean of the follow-up word across conditions.



Barplot of the main word with standard error as errorbars.

```{r barplot main word}
#Main word kiss/save
ggplot(the_df, aes(x = ks_df$Condition, y = ks_df$Response_Time)) +
  theme_minimal() +
    labs(x = "Condition", y = "Response time") +
  geom_bar(aes(fill= Condition), stat='summary', fun.y = mean, width = 0.5) +
  stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1) +
  ggtitle("The mean of the main word 'kiss/save' across conditions")
```


The barplot seem to show some difference of the main-word across the condition. But unfortunately for our hypothesis it seems to be taking longer to read the normal word than the surprising word. 



**T-test**

Making t-test to test the statiscally significance of compairing the means. I use the independent t-test from WRS2-package as the assumption of normality is violated and we have a between-participant design. 

```{r t-tests}
#the_df
WRS2::yuen(Response_Time ~ Condition, data = the_df)

#ks_df
WRS2::yuen(Response_Time ~ Condition, data = ks_df)
```


In compairing the means of the follow-up word across condition, I have found no difference of the means *t*(9.8) = 0.3, p > .05.  

In compairing the means of the main word across condition, I have found no statistical significance of difference between the means *t*(5.6) = 1.1, p > .05.


**Conclusion part 2**

I have found no statistically signifance in the reading time of a semantically different word in our experiment. This could be because, the suprise-word appear so late in the text, and as we saw in the correlation test of word number, there is a decrease of response time as the word number increases. I also have a small dataset, which could have an impact on the results.